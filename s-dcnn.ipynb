{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as k\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Reshape,Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.decomposition import PCA\n",
    "from data_pretreat import handle_data\n",
    "from PIL import Image\n",
    "\n",
    "k.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6143, 200)\n",
      "(6143, 1)\n",
      "(4106, 200)\n",
      "(4106, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x,train_y,test_x,test_y=handle_data(train_scale=0.6)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "\n",
    "num_classes=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6143, 200)\n",
      "(6143, 16)\n",
      "(4106, 200)\n",
      "(4106, 16)\n"
     ]
    }
   ],
   "source": [
    "data_all=np.r_[train_x,test_x]\n",
    "data_all=data_all/np.max(data_all)\n",
    "train_x=data_all[0:train_x.shape[0],:]\n",
    "test_x=data_all[train_x.shape[0]:,:]\n",
    "train_y=np_utils.to_categorical(train_y)[:,1:17]\n",
    "test_y =np_utils.to_categorical(test_y)[:,1:17]\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_dcnn_model(input_shape,num_classes=16):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(196, input_shape=(input_shape,), activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Dense(196, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Reshape((14, 14, 1)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    #model.add(Dropout(0.25))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 196)               39396     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 14, 14, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 12, 12, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                1040      \n",
      "=================================================================\n",
      "Total params: 272,436\n",
      "Trainable params: 272,436\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(6143, 200)\n",
      "(6143, 16)\n",
      "(4106, 200)\n",
      "(4106, 16)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "6143/6143 [==============================] - 2s 280us/sample - loss: 2.0401 - acc: 0.3228\n",
      "Epoch 2/100\n",
      "6143/6143 [==============================] - 1s 128us/sample - loss: 1.6407 - acc: 0.4109\n",
      "Epoch 3/100\n",
      "6143/6143 [==============================] - 1s 126us/sample - loss: 1.5384 - acc: 0.4355\n",
      "Epoch 4/100\n",
      "6143/6143 [==============================] - 1s 128us/sample - loss: 1.4704 - acc: 0.4408\n",
      "Epoch 5/100\n",
      "6143/6143 [==============================] - 1s 130us/sample - loss: 1.4317 - acc: 0.4521\n",
      "Epoch 6/100\n",
      "6143/6143 [==============================] - 1s 130us/sample - loss: 1.4172 - acc: 0.4482\n",
      "Epoch 7/100\n",
      "6143/6143 [==============================] - 1s 134us/sample - loss: 1.3778 - acc: 0.4612\n",
      "Epoch 8/100\n",
      "6143/6143 [==============================] - 1s 131us/sample - loss: 1.3510 - acc: 0.4623\n",
      "Epoch 9/100\n",
      "6143/6143 [==============================] - 1s 133us/sample - loss: 1.3235 - acc: 0.4750\n",
      "Epoch 10/100\n",
      "6143/6143 [==============================] - 1s 155us/sample - loss: 1.2957 - acc: 0.4802\n",
      "Epoch 11/100\n",
      "6143/6143 [==============================] - 1s 134us/sample - loss: 1.2726 - acc: 0.4975\n",
      "Epoch 12/100\n",
      "6143/6143 [==============================] - 1s 133us/sample - loss: 1.2521 - acc: 0.5022\n",
      "Epoch 13/100\n",
      "6143/6143 [==============================] - 1s 136us/sample - loss: 1.2254 - acc: 0.5214\n",
      "Epoch 14/100\n",
      "6143/6143 [==============================] - 1s 139us/sample - loss: 1.1881 - acc: 0.5260\n",
      "Epoch 15/100\n",
      "6143/6143 [==============================] - 1s 132us/sample - loss: 1.1794 - acc: 0.5359\n",
      "Epoch 16/100\n",
      "6143/6143 [==============================] - 1s 132us/sample - loss: 1.1611 - acc: 0.5434\n",
      "Epoch 17/100\n",
      "6143/6143 [==============================] - 1s 135us/sample - loss: 1.1513 - acc: 0.5387\n",
      "Epoch 18/100\n",
      "6143/6143 [==============================] - 1s 145us/sample - loss: 1.1305 - acc: 0.5535\n",
      "Epoch 19/100\n",
      "6143/6143 [==============================] - 1s 135us/sample - loss: 1.1165 - acc: 0.5572\n",
      "Epoch 20/100\n",
      "6143/6143 [==============================] - 1s 134us/sample - loss: 1.1191 - acc: 0.5642\n",
      "Epoch 21/100\n",
      "6143/6143 [==============================] - 1s 133us/sample - loss: 1.0995 - acc: 0.5654\n",
      "Epoch 22/100\n",
      "6143/6143 [==============================] - 1s 134us/sample - loss: 1.0913 - acc: 0.5632\n",
      "Epoch 23/100\n",
      "6143/6143 [==============================] - 1s 137us/sample - loss: 1.0768 - acc: 0.5751\n",
      "Epoch 24/100\n",
      "6143/6143 [==============================] - 1s 139us/sample - loss: 1.0724 - acc: 0.5719\n",
      "Epoch 25/100\n",
      "6143/6143 [==============================] - 1s 136us/sample - loss: 1.0521 - acc: 0.5787\n",
      "Epoch 26/100\n",
      "6143/6143 [==============================] - 1s 136us/sample - loss: 1.0428 - acc: 0.5865\n",
      "Epoch 27/100\n",
      "6143/6143 [==============================] - 1s 139us/sample - loss: 1.0380 - acc: 0.5846\n",
      "Epoch 28/100\n",
      "6143/6143 [==============================] - 1s 132us/sample - loss: 1.0343 - acc: 0.5872\n",
      "Epoch 29/100\n",
      "6143/6143 [==============================] - 1s 131us/sample - loss: 1.0389 - acc: 0.5917\n",
      "Epoch 30/100\n",
      "6143/6143 [==============================] - 1s 136us/sample - loss: 1.0168 - acc: 0.5953\n",
      "Epoch 31/100\n",
      "6143/6143 [==============================] - 1s 136us/sample - loss: 1.0021 - acc: 0.6083\n",
      "Epoch 32/100\n",
      "6143/6143 [==============================] - 1s 148us/sample - loss: 0.9907 - acc: 0.6087\n",
      "Epoch 33/100\n",
      "6143/6143 [==============================] - 1s 138us/sample - loss: 0.9980 - acc: 0.5992\n",
      "Epoch 34/100\n",
      "6143/6143 [==============================] - 1s 128us/sample - loss: 0.9789 - acc: 0.6124\n",
      "Epoch 35/100\n",
      "6143/6143 [==============================] - 1s 127us/sample - loss: 0.9896 - acc: 0.6078\n",
      "Epoch 36/100\n",
      "6143/6143 [==============================] - 1s 129us/sample - loss: 0.9680 - acc: 0.6181\n",
      "Epoch 37/100\n",
      "6143/6143 [==============================] - 1s 134us/sample - loss: 0.9778 - acc: 0.6165\n",
      "Epoch 38/100\n",
      "6143/6143 [==============================] - 1s 133us/sample - loss: 0.9570 - acc: 0.6214\n",
      "Epoch 39/100\n",
      "6143/6143 [==============================] - 1s 131us/sample - loss: 0.9491 - acc: 0.6220\n",
      "Epoch 40/100\n",
      "6143/6143 [==============================] - 1s 131us/sample - loss: 0.9464 - acc: 0.6293\n",
      "Epoch 41/100\n",
      "6143/6143 [==============================] - 1s 137us/sample - loss: 0.9544 - acc: 0.6266\n",
      "Epoch 42/100\n",
      "6143/6143 [==============================] - 1s 133us/sample - loss: 0.9440 - acc: 0.6274\n",
      "Epoch 43/100\n",
      "6143/6143 [==============================] - 1s 137us/sample - loss: 0.9221 - acc: 0.6378\n",
      "Epoch 44/100\n",
      "6143/6143 [==============================] - 1s 130us/sample - loss: 0.9408 - acc: 0.6254\n",
      "Epoch 45/100\n",
      "6143/6143 [==============================] - 1s 141us/sample - loss: 0.9205 - acc: 0.6332\n",
      "Epoch 46/100\n",
      "6143/6143 [==============================] - 1s 133us/sample - loss: 0.9095 - acc: 0.6438\n",
      "Epoch 47/100\n",
      "6143/6143 [==============================] - 1s 132us/sample - loss: 0.9061 - acc: 0.6389\n",
      "Epoch 48/100\n",
      "6143/6143 [==============================] - 1s 129us/sample - loss: 0.9074 - acc: 0.6383\n",
      "Epoch 49/100\n",
      "6143/6143 [==============================] - 1s 143us/sample - loss: 0.9035 - acc: 0.6446\n",
      "Epoch 50/100\n",
      "6143/6143 [==============================] - 1s 135us/sample - loss: 0.9012 - acc: 0.6492\n",
      "Epoch 51/100\n",
      "6143/6143 [==============================] - 1s 132us/sample - loss: 0.8942 - acc: 0.6507\n",
      "Epoch 52/100\n",
      "6143/6143 [==============================] - 1s 128us/sample - loss: 0.8913 - acc: 0.6549\n",
      "Epoch 53/100\n",
      "6143/6143 [==============================] - 1s 132us/sample - loss: 0.8775 - acc: 0.6586\n",
      "Epoch 54/100\n",
      "6143/6143 [==============================] - 1s 127us/sample - loss: 0.8698 - acc: 0.6629\n",
      "Epoch 55/100\n",
      "6143/6143 [==============================] - 1s 128us/sample - loss: 0.8709 - acc: 0.6594\n",
      "Epoch 56/100\n",
      "6143/6143 [==============================] - 1s 130us/sample - loss: 0.8685 - acc: 0.6583\n",
      "Epoch 57/100\n",
      "6143/6143 [==============================] - 1s 134us/sample - loss: 0.8615 - acc: 0.6625\n",
      "Epoch 58/100\n",
      "6143/6143 [==============================] - 1s 131us/sample - loss: 0.8469 - acc: 0.6705\n",
      "Epoch 59/100\n",
      "6143/6143 [==============================] - 1s 132us/sample - loss: 0.8629 - acc: 0.6647\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6143/6143 [==============================] - 1s 134us/sample - loss: 0.8465 - acc: 0.6643\n",
      "Epoch 61/100\n",
      "6143/6143 [==============================] - 1s 126us/sample - loss: 0.8524 - acc: 0.6692\n",
      "Epoch 62/100\n",
      "6143/6143 [==============================] - 1s 130us/sample - loss: 0.8493 - acc: 0.6655\n",
      "Epoch 63/100\n",
      "6143/6143 [==============================] - 1s 129us/sample - loss: 0.8394 - acc: 0.6764\n",
      "Epoch 64/100\n",
      "6143/6143 [==============================] - 1s 127us/sample - loss: 0.8314 - acc: 0.6756\n",
      "Epoch 65/100\n",
      "6143/6143 [==============================] - 1s 128us/sample - loss: 0.8363 - acc: 0.6757\n",
      "Epoch 66/100\n",
      "6143/6143 [==============================] - 1s 131us/sample - loss: 0.8316 - acc: 0.6775\n",
      "Epoch 67/100\n",
      "6143/6143 [==============================] - 1s 128us/sample - loss: 0.8330 - acc: 0.6749\n",
      "Epoch 68/100\n",
      "6143/6143 [==============================] - 1s 128us/sample - loss: 0.8181 - acc: 0.6803\n",
      "Epoch 69/100\n",
      "6143/6143 [==============================] - 1s 130us/sample - loss: 0.8068 - acc: 0.6923\n",
      "Epoch 70/100\n",
      "6143/6143 [==============================] - 1s 129us/sample - loss: 0.8086 - acc: 0.6818\n",
      "Epoch 71/100\n",
      "6143/6143 [==============================] - 1s 128us/sample - loss: 0.7950 - acc: 0.6933\n",
      "Epoch 72/100\n",
      "6143/6143 [==============================] - 1s 128us/sample - loss: 0.8177 - acc: 0.6819\n",
      "Epoch 73/100\n",
      "6143/6143 [==============================] - 1s 131us/sample - loss: 0.7931 - acc: 0.6948\n",
      "Epoch 74/100\n",
      "6143/6143 [==============================] - 1s 128us/sample - loss: 0.8123 - acc: 0.6850\n",
      "Epoch 75/100\n",
      "6143/6143 [==============================] - 1s 126us/sample - loss: 0.7957 - acc: 0.6931\n",
      "Epoch 76/100\n",
      "6143/6143 [==============================] - 1s 127us/sample - loss: 0.7968 - acc: 0.6935\n",
      "Epoch 77/100\n",
      "6143/6143 [==============================] - 1s 128us/sample - loss: 0.7916 - acc: 0.6943\n",
      "Epoch 78/100\n",
      "6143/6143 [==============================] - 1s 128us/sample - loss: 0.7901 - acc: 0.6982\n",
      "Epoch 79/100\n",
      "6143/6143 [==============================] - 1s 129us/sample - loss: 0.7935 - acc: 0.6897\n",
      "Epoch 80/100\n",
      "6143/6143 [==============================] - 1s 130us/sample - loss: 0.7816 - acc: 0.6998\n",
      "Epoch 81/100\n",
      "6143/6143 [==============================] - 1s 129us/sample - loss: 0.7727 - acc: 0.6974\n",
      "Epoch 82/100\n",
      "6143/6143 [==============================] - 1s 126us/sample - loss: 0.7819 - acc: 0.6953\n",
      "Epoch 83/100\n",
      "6143/6143 [==============================] - 1s 129us/sample - loss: 0.7618 - acc: 0.7089\n",
      "Epoch 84/100\n",
      "6143/6143 [==============================] - 1s 129us/sample - loss: 0.7624 - acc: 0.7050\n",
      "Epoch 85/100\n",
      "6143/6143 [==============================] - 1s 129us/sample - loss: 0.7596 - acc: 0.7071\n",
      "Epoch 86/100\n",
      "6143/6143 [==============================] - 1s 129us/sample - loss: 0.7717 - acc: 0.6998\n",
      "Epoch 87/100\n",
      "6143/6143 [==============================] - 1s 127us/sample - loss: 0.7776 - acc: 0.6953\n",
      "Epoch 88/100\n",
      "6143/6143 [==============================] - 1s 128us/sample - loss: 0.7552 - acc: 0.7104\n",
      "Epoch 89/100\n",
      "6143/6143 [==============================] - 1s 134us/sample - loss: 0.7657 - acc: 0.7018\n",
      "Epoch 90/100\n",
      "6143/6143 [==============================] - 1s 133us/sample - loss: 0.7433 - acc: 0.7133\n",
      "Epoch 91/100\n",
      "6143/6143 [==============================] - 1s 129us/sample - loss: 0.7499 - acc: 0.7107\n",
      "Epoch 92/100\n",
      "6143/6143 [==============================] - 1s 132us/sample - loss: 0.7515 - acc: 0.7132\n",
      "Epoch 93/100\n",
      "6143/6143 [==============================] - 1s 129us/sample - loss: 0.7613 - acc: 0.7011\n",
      "Epoch 94/100\n",
      "6143/6143 [==============================] - 1s 136us/sample - loss: 0.7478 - acc: 0.7120\n",
      "Epoch 95/100\n",
      "6143/6143 [==============================] - 1s 148us/sample - loss: 0.7506 - acc: 0.7124\n",
      "Epoch 96/100\n",
      "6143/6143 [==============================] - 1s 135us/sample - loss: 0.7345 - acc: 0.7189\n",
      "Epoch 97/100\n",
      "6143/6143 [==============================] - 1s 144us/sample - loss: 0.7344 - acc: 0.7143\n",
      "Epoch 98/100\n",
      "6143/6143 [==============================] - 1s 127us/sample - loss: 0.7504 - acc: 0.7112\n",
      "Epoch 99/100\n",
      "6143/6143 [==============================] - 1s 130us/sample - loss: 0.7238 - acc: 0.7205\n",
      "Epoch 100/100\n",
      "6143/6143 [==============================] - 1s 128us/sample - loss: 0.7434 - acc: 0.7132\n",
      "Saving model to disk \n",
      "\n",
      "4106/4106 [==============================] - 0s 59us/sample - loss: 0.8752 - acc: 0.6488\n",
      "loss: 0.875207240372321\n",
      "accuracy: 0.64880663\n"
     ]
    }
   ],
   "source": [
    "s_dcnn_model=s_dcnn_model(train_x.shape[1])\n",
    "s_dcnn_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  #optimizer=keras.optimizers.Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "\n",
    "s_dcnn_model.fit(train_x, train_y,\n",
    "            batch_size=32,\n",
    "            epochs=100,\n",
    "            verbose=1)\n",
    "    \n",
    "print(\"Saving model to disk \\n\")\n",
    "path=\"s_dcnn_model.h5\"\n",
    "s_dcnn_model.save(path)\n",
    "\n",
    "loss,accuracy=s_dcnn_model.evaluate(test_x, test_y)\n",
    "print('loss:', loss)\n",
    "print('accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
